# diagnose_fix.py
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

print("=" * 70)
print("üîç DIAGN√ìSTICO Y CORRECCI√ìN DE PROBLEMAS")
print("=" * 70)

# 1. Cargar datos y verificar
print("\n1. üìÇ CARGANDO Y ANALIZANDO DATOS ORIGINALES...")
data_path = Path("processed_data/lol_processed_data.csv")

if not data_path.exists():
    print("‚ùå No se encontraron datos procesados")
    exit()

df = pd.read_csv(data_path)
print(f"‚úÖ Datos cargados: {df.shape[0]:,} filas √ó {df.shape[1]} columnas")

# 2. An√°lisis detallado de los datos
print("\n2. üìä AN√ÅLISIS DETALLADO DEL DATASET")
print("-" * 40)

print("üìã Primeras 5 filas:")
print(df.head())

print(f"\nüî¢ Tipos de datos:")
print(df.dtypes.value_counts())

print(f"\n‚ùì Valores nulos:")
print(df.isnull().sum().sort_values(ascending=False).head(10))

print(f"\nüéØ Distribuci√≥n de BlueWin:")
print(df['BlueWin'].value_counts(normalize=True))

# 3. Buscar problemas espec√≠ficos
print("\n3. üîç BUSCANDO PROBLEMAS COMUNES")
print("-" * 40)

# 3.1. Verificar si hay columnas constantes
constant_cols = []
for col in df.columns:
    if df[col].nunique() == 1:
        constant_cols.append(col)

if constant_cols:
    print(f"‚ö†Ô∏è  Columnas constantes encontradas: {constant_cols}")
else:
    print("‚úÖ No hay columnas constantes")

# 3.2. Verificar correlaciones extremas
print(f"\nüìà Matriz de correlaciones (solo primeras 10x10):")
corr_matrix = df.corr()
plt.figure(figsize=(10, 8))
sns.heatmap(corr_matrix.iloc[:10, :10], annot=True, fmt='.2f', cmap='coolwarm', center=0)
plt.title('Matriz de Correlaci√≥n (primeras 10 caracter√≠sticas)')
plt.tight_layout()
plt.savefig('processed_data/correlation_heatmap.png', dpi=150)
plt.show()

# Buscar correlaciones perfectas (>0.95 o <-0.95)
high_corr_pairs = []
for i in range(len(corr_matrix.columns)):
    for j in range(i+1, len(corr_matrix.columns)):
        if abs(corr_matrix.iloc[i, j]) > 0.95:
            high_corr_pairs.append((corr_matrix.columns[i], corr_matrix.columns[j], corr_matrix.iloc[i, j]))

if high_corr_pairs:
    print(f"‚ö†Ô∏è  Correlaciones extremas encontradas:")
    for col1, col2, corr in high_corr_pairs[:5]:  # Mostrar solo 5
        print(f"  {col1} ‚Üî {col2}: {corr:.3f}")
else:
    print("‚úÖ No hay correlaciones extremas")

# 3.3. Verificar si BlueWin est√° en los datos de alguna manera
print(f"\nüéØ Verificando variable objetivo BlueWin:")
print(f"Valores √∫nicos: {df['BlueWin'].unique()}")
print(f"Distribuci√≥n: {df['BlueWin'].value_counts()}")

# 4. Verificar si hay data leakage
print("\n4. üö® BUSCANDO DATA LEAKAGE")
print("-" * 40)

# Verificar si hay caracter√≠sticas que contienen informaci√≥n del futuro
leakage_suspects = []
for col in df.columns:
    if col != 'BlueWin':
        # Si la correlaci√≥n es casi perfecta, sospechoso
        corr = abs(df[col].corr(df['BlueWin']))
        if corr > 0.9:
            leakage_suspects.append((col, corr))

if leakage_suspects:
    print("‚ö†Ô∏è  POSIBLE DATA LEAKAGE DETECTADO!")
    print("Caracter√≠sticas altamente correlacionadas con BlueWin:")
    for col, corr in leakage_suspects:
        print(f"  {col}: correlaci√≥n = {corr:.4f}")
        
    # Mostrar ejemplos
    suspect_col = leakage_suspects[0][0]
    print(f"\nüîç Analizando {suspect_col}:")
    print(f"  Valores √∫nicos: {df[suspect_col].nunique()}")
    print(f"  Min: {df[suspect_col].min()}, Max: {df[suspect_col].max()}")
    print(f"  Ejemplos cuando BlueWin=1: {df[df['BlueWin']==1][suspect_col].iloc[:5].values}")
    print(f"  Ejemplos cuando BlueWin=0: {df[df['BlueWin']==0][suspect_col].iloc[:5].values}")
else:
    print("‚úÖ No se detect√≥ data leakage obvio")

# 5. Crear dataset corregido
print("\n5. üõ†Ô∏è  CREANDO DATASET CORREGIDO")
print("-" * 40)

# Primero, vamos a analizar las caracter√≠sticas que tenemos
print("üìã Lista completa de caracter√≠sticas:")
for i, col in enumerate(df.columns, 1):
    print(f"{i:3d}. {col}")

# Identificar caracter√≠sticas problem√°ticas
# Basado en los resultados, probablemente hay caracter√≠sticas que son
# derivadas directamente del resultado

# Vamos a crear un dataset m√°s simple y seguro
print("\nüîß Creando caracter√≠sticas seguras...")

# Separar el objetivo
y = df['BlueWin'].copy()

# Crear X con caracter√≠sticas que deber√≠an ser seguras
# Eliminamos cualquier cosa que parezca un conteo o resultado
safe_features = []

for col in df.columns:
    if col == 'BlueWin':
        continue
    
    col_lower = col.lower()
    
    # Excluir caracter√≠sticas sospechosas
    exclude_keywords = ['diff', 'kills', 'tower', 'dragon', 'baron', 'herald', 'win']
    
    is_safe = True
    for keyword in exclude_keywords:
        if keyword in col_lower:
            is_safe = False
            print(f"  Excluyendo {col} (contiene '{keyword}')")
            break
    
    if is_safe:
        safe_features.append(col)

print(f"\n‚úÖ Caracter√≠sticas seguras seleccionadas: {len(safe_features)}")
print(f"Caracter√≠sticas: {safe_features}")

X_safe = df[safe_features].copy()

# Verificar correlaciones nuevamente
print(f"\nüìä Correlaciones con BlueWin (caracter√≠sticas seguras):")
correlations = X_safe.apply(lambda x: x.corr(y))
print(correlations.sort_values(ascending=False).head(10))

# 6. Probar modelo simple para verificar
print("\n6. üß™ PRUEBA R√ÅPIDA CON MODELO SIMPLE")
print("-" * 40)

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# Dividir datos
X_train, X_test, y_train, y_test = train_test_split(
    X_safe, y, test_size=0.2, random_state=42, stratify=y
)

print(f"Entrenamiento: {X_train.shape[0]:,} muestras")
print(f"Prueba: {X_test.shape[0]:,} muestras")

# Modelo simple
model = LogisticRegression(max_iter=1000, random_state=42)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

print(f"\nüìà Resultado con caracter√≠sticas seguras:")
print(f"  Accuracy: {accuracy:.4f}")
print(f"  Precisi√≥n esperada si predij√©ramos siempre azul: {y.mean():.4f}")

if accuracy > y.mean() + 0.05:
    print("  ‚úÖ El modelo aprende algo √∫til")
elif accuracy > y.mean():
    print("  ‚ö†Ô∏è  El modelo es marginalmente mejor que predecir siempre azul")
else:
    print("  ‚ùå El modelo es peor que predecir siempre azul")

# 7. Crear dataset con mejores caracter√≠sticas
print("\n7. üèóÔ∏è  CREANDO DATASET MEJORADO")
print("-" * 40)

# Vamos a recrear caracter√≠sticas desde cero, evitando data leakage
print("üî® Reconstruyendo caracter√≠sticas desde los datos originales...")

# Primero necesitamos cargar los datos originales
original_data_path = Path("archive")
if not original_data_path.exists():
    print("‚ùå No se encuentra la carpeta 'archives' con datos originales")
else:
    print("‚úÖ Carpeta 'archives' encontrada")
    
    # Cargar TeamMatchTbl para caracter√≠sticas de composici√≥n
    team_df_path = original_data_path / "TeamMatchTbl.csv"
    if team_df_path.exists():
        team_df = pd.read_csv(team_df_path)
        print(f"‚úÖ TeamMatchTbl cargado: {team_df.shape[0]:,} filas")
        
        # Crear caracter√≠sticas seguras de composici√≥n
        print("\nüéØ Creando caracter√≠sticas de composici√≥n seguras:")
        
        # 1. Diversidad de campeones por equipo
        blue_champs = ['B1Champ', 'B2Champ', 'B3Champ', 'B4Champ', 'B5Champ']
        red_champs = ['R1Champ', 'R2Champ', 'R3Champ', 'R4Champ', 'R5Champ']
        
        features_new = pd.DataFrame()
        features_new['MatchFk'] = team_df['MatchFk']
        
        # Diversidad (cu√°ntos campeones √∫nicos)
        features_new['Blue_UniqueChamps'] = team_df[blue_champs].nunique(axis=1)
        features_new['Red_UniqueChamps'] = team_df[red_champs].nunique(axis=1)
        
        # ID promedio de campeones (proxy de antig√ºedad)
        features_new['Blue_AvgChampId'] = team_df[blue_champs].mean(axis=1)
        features_new['Red_AvgChampId'] = team_df[red_champs].mean(axis=1)
        
        # Diferencia en diversidad
        features_new['UniqueChamps_Diff'] = features_new['Blue_UniqueChamps'] - features_new['Red_UniqueChamps']
        features_new['AvgChampId_Diff'] = features_new['Blue_AvgChampId'] - features_new['Red_AvgChampId']
        
        # 2. Informaci√≥n de regi√≥n (extraer del MatchFk)
        features_new['Region'] = team_df['MatchFk'].str.extract(r'^([A-Z]+)')[0]
        # Codificar regiones principales
        regions_to_code = {'EUW': 0, 'NA': 1, 'EUN': 2, 'KR': 3, 'BR': 4}
        features_new['Region_Code'] = features_new['Region'].map(regions_to_code).fillna(5)
        
        # 3. Variable objetivo
        features_new['BlueWin'] = team_df['BlueWin']
        
        print(f"‚úÖ Caracter√≠sticas creadas: {features_new.shape[1]} columnas")
        print(f"üìã Caracter√≠sticas: {list(features_new.columns)}")
        
        # Eliminar columnas no num√©ricas para ML
        features_ml = features_new.drop(['MatchFk', 'Region'], axis=1)
        
        # Verificar correlaciones
        print(f"\nüìä Correlaciones con BlueWin:")
        correlations_new = features_ml.corr()['BlueWin'].drop('BlueWin').sort_values(ascending=False)
        print(correlations_new.head(10))
        
        # Guardar nuevo dataset
        output_path = Path("processed_data/lol_safe_features.csv")
        features_ml.to_csv(output_path, index=False)
        print(f"\nüíæ Dataset seguro guardado en: {output_path}")
        
        # Probar modelo r√°pido
        print("\nüß™ Probando modelo con caracter√≠sticas seguras...")
        
        X_new = features_ml.drop('BlueWin', axis=1)
        y_new = features_ml['BlueWin']
        
        X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(
            X_new, y_new, test_size=0.2, random_state=42, stratify=y_new
        )
        
        model_new = LogisticRegression(max_iter=1000, random_state=42)
        model_new.fit(X_train_new, y_train_new)
        
        y_pred_new = model_new.predict(X_test_new)
        accuracy_new = accuracy_score(y_test_new, y_pred_new)
        
        print(f"üìà Resultados:")
        print(f"  Accuracy: {accuracy_new:.4f}")
        print(f"  Mejora sobre predecir siempre azul: {accuracy_new - y_new.mean():.4f}")
        print(f"  Precisi√≥n baseline (siempre azul): {y_new.mean():.4f}")
        
        # 8. Entrenar varios modelos con datos seguros
        print("\n8. ü§ñ ENTRENANDO MODELOS CON DATOS SEGUROS")
        print("-" * 40)
        
        from sklearn.ensemble import RandomForestClassifier
        from xgboost import XGBClassifier
        from sklearn.metrics import classification_report
        
        models_to_test = {
            'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),
            'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
            'XGBoost': XGBClassifier(n_estimators=100, random_state=42, use_label_encoder=False, eval_metric='logloss')
        }
        
        print("üìä Resultados de modelos con caracter√≠sticas seguras:")
        print("-" * 60)
        
        results_safe = []
        for name, model in models_to_test.items():
            model.fit(X_train_new, y_train_new)
            y_pred = model.predict(X_test_new)
            accuracy = accuracy_score(y_test_new, y_pred)
            results_safe.append((name, accuracy))
            
            if name == 'Random Forest' and hasattr(model, 'feature_importances_'):
                # Mostrar importancia de caracter√≠sticas
                print(f"\nüîç Importancia de caracter√≠sticas ({name}):")
                importances = pd.DataFrame({
                    'feature': X_new.columns,
                    'importance': model.feature_importances_
                }).sort_values('importance', ascending=False)
                
                for i, row in importances.head().iterrows():
                    print(f"  {row['feature']}: {row['importance']:.4f}")
        
        print("\n" + "-" * 60)
        print("üèÜ COMPARACI√ìN DE MODELOS (caracter√≠sticas seguras):")
        for name, accuracy in results_safe:
            print(f"  {name:20s}: Accuracy = {accuracy:.4f}")
        
        # 9. Recomendaciones finales
        print("\n9. üí° RECOMENDACIONES Y PR√ìXIMOS PASOS")
        print("-" * 40)
        
        print("""
        üìå PROBLEMAS IDENTIFICADOS:
        1. Data leakage probable: caracter√≠sticas como *Diff pueden contener
           informaci√≥n del resultado final
        2. Overfitting severo en algunos modelos
        3. Necesitamos caracter√≠sticas que est√©n disponibles ANTES del resultado
        
        üéØ ESTRATEGIA CORREGIDA:
        1. Usar solo caracter√≠sticas disponibles al inicio de la partida:
           - Composici√≥n de campeones
           - Informaci√≥n de regi√≥n
           - Stats hist√≥ricos (si los calculamos correctamente)
        
        2. NO usar:
           - Kills, torretas, dragones, barones (son resultados, no predictores)
           - Diferencias (*_Diff) que se calculan del resultado
        
        üîß MEJORAS SUGERIDAS:
        1. Calcular win rates hist√≥ricos de campeones (con cuidado temporal)
        2. A√±adir informaci√≥n de roles/lanes
        3. Incluir sinergias entre campeones
        4. Usar informaci√≥n de temporada/patch
        
        üöÄ PR√ìXIMOS PASOS INMEDIATOS:
        1. Entrenar con el dataset seguro (lol_safe_features.csv)
        2. A√±adir caracter√≠sticas hist√≥ricas calculadas correctamente
        3. Implementar validaci√≥n temporal (no aleatoria)
        4. Probar modelos m√°s complejos con datos seguros
        """)
        
        # 10. Script para el siguiente paso
        print("\n10. üìú SCRIPT PARA EL SIGUIENTE PASO")
        print("-" * 40)
        
        next_script = """
        # next_step.py - Mejorar caracter√≠sticas y entrenar modelos robustos
        
        import pandas as pd
        import numpy as np
        from sklearn.model_selection import train_test_split, TimeSeriesSplit
        from sklearn.ensemble import RandomForestClassifier
        from xgboost import XGBClassifier
        from sklearn.metrics import accuracy_score, classification_report
        import joblib
        
        # 1. Cargar datos seguros
        df = pd.read_csv("processed_data/lol_safe_features.csv")
        
        # 2. A√±adir caracter√≠sticas hist√≥ricas (sin data leakage)
        # Esto requiere procesar los datos originales en orden temporal
        
        # 3. Dividir temporalmente (no aleatoriamente)
        # Ordenar por MatchFk si contiene timestamp
        # df = df.sort_values('MatchFk')
        
        # 4. Entrenar con validaci√≥n temporal
        X = df.drop('BlueWin', axis=1)
        y = df['BlueWin']
        
        # Dividir 80/20 temporalmente
        split_idx = int(len(X) * 0.8)
        X_train = X.iloc[:split_idx]
        X_test = X.iloc[split_idx:]
        y_train = y.iloc[:split_idx]
        y_test = y.iloc[split_idx:]
        
        # 5. Entrenar modelo robusto
        model = XGBClassifier(
            n_estimators=200,
            max_depth=5,
            learning_rate=0.1,
            random_state=42,
            use_label_encoder=False,
            eval_metric='logloss'
        )
        
        model.fit(X_train, y_train)
        
        # 6. Evaluar
        y_pred = model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        print(f"Accuracy (validaci√≥n temporal): {accuracy:.4f}")
         
        # 7. Guardar modelo
        joblib.dump(model, "processed_data/robust_model.pkl")
        """
        
        print(next_script)
        
    else:
        print("‚ùå No se encontr√≥ TeamMatchTbl.csv")

print("\n" + "="*70)
print("‚úÖ DIAGN√ìSTICO COMPLETADO")
print("="*70)